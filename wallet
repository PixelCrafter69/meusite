#!/usr/bin/env python3
"""
Sistema Profissional de Verifica√ß√£o de Carteiras Bitcoin - Vers√£o Otimizada
Verifica milhares de carteiras por minuto usando frases mnem√≥nicas BIP39
com performance m√°xima, seguran√ßa e robustez aprimoradas.
"""

import os
import json
import time
import sqlite3
import hashlib
import asyncio
import aiohttp
import logging
import random
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from multiprocessing import cpu_count, Manager
from threading import Lock, RLock
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from collections import deque
import configparser
from pathlib import Path

# Bibliotecas criptogr√°ficas otimizadas
from mnemonic import Mnemonic
from bip_utils import Bip39SeedGenerator, Bip44, Bip44Coins, Bip44Changes
import segwit_addr  # Para endere√ßos Bech32 corretos
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from Crypto.Protocol.KDF import PBKDF2

# Configura√ß√£o
CONFIG_FILE = "config.ini"
DEFAULT_CONFIG = {
    'database': {
        'path': 'wallets.db',
        'backup_interval': '3600',  # segundos
        'batch_size': '1000'
    },
    'api': {
        'timeout': '10',
        'max_retries': '3',
        'backoff_factor': '2',
        'rate_limit_buffer': '0.8'
    },
    'scanner': {
        'max_workers': str(cpu_count() * 4),
        'cache_size': '100000',
        'stats_interval': '60'
    },
    'security': {
        'encrypt_phrases': 'true',
        'key_derivation_rounds': '100000'
    }
}

def load_config() -> configparser.ConfigParser:
    """Carrega configura√ß√£o do ficheiro"""
    config = configparser.ConfigParser()
    
    if not os.path.exists(CONFIG_FILE):
        # Criar configura√ß√£o padr√£o
        for section, options in DEFAULT_CONFIG.items():
            config.add_section(section)
            for key, value in options.items():
                config.set(section, key, value)
        
        with open(CONFIG_FILE, 'w') as f:
            config.write(f)
        
        print(f"‚úÖ Ficheiro de configura√ß√£o criado: {CONFIG_FILE}")
    else:
        config.read(CONFIG_FILE)
    
    return config

# Configura√ß√£o global
CONFIG = load_config()

# Configura√ß√£o de logging melhorada
def setup_logging():
    """Configura sistema de logging avan√ßado"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # Criar diret√≥rio de logs se n√£o existir
    Path("logs").mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler(f'logs/wallet_scanner_{datetime.now().strftime("%Y%m%d")}.log'),
            logging.StreamHandler()
        ]
    )
    
    # Logger espec√≠fico para resultados importantes
    results_logger = logging.getLogger('results')
    results_handler = logging.FileHandler('logs/found_wallets.log')
    results_handler.setFormatter(logging.Formatter(log_format))
    results_logger.addHandler(results_handler)
    results_logger.setLevel(logging.INFO)
    
    return logging.getLogger(__name__), results_logger

logger, results_logger = setup_logging()

@dataclass
class WalletResult:
    """Estrutura otimizada para armazenar resultados de verifica√ß√£o"""
    phrase_hash: str  # Hash da frase para seguran√ßa
    address: str
    balance: float
    timestamp: str
    derivation_path: str = "m/44'/0'/0'/0/0"
    address_type: str = "P2PKH"
    encrypted_phrase: Optional[bytes] = None

class SecurityManager:
    """Gerenciador de seguran√ßa para encripta√ß√£o de frases"""
    
    def __init__(self, password: str = None):
        self.password = password or os.getenv('WALLET_SCANNER_KEY', 'default_key_change_me')
        self.key = PBKDF2(
            self.password, 
            b'wallet_scanner_salt',
            dkLen=32,
            count=int(CONFIG.get('security', 'key_derivation_rounds'))
        )
    
    def encrypt_phrase(self, phrase: str) -> bytes:
        """Encripta uma frase mnem√≥nica"""
        cipher = AES.new(self.key, AES.MODE_GCM)
        ciphertext, tag = cipher.encrypt_and_digest(phrase.encode())
        return cipher.nonce + tag + ciphertext
    
    def decrypt_phrase(self, encrypted_data: bytes) -> str:
        """Desencripta uma frase mnem√≥nica"""
        nonce = encrypted_data[:16]
        tag = encrypted_data[16:32]
        ciphertext = encrypted_data[32:]
        
        cipher = AES.new(self.key, AES.MODE_GCM, nonce=nonce)
        phrase = cipher.decrypt_and_verify(ciphertext, tag)
        return phrase.decode()

class HighPerformanceCache:
    """Cache de alta performance para frases usadas"""
    
    def __init__(self, max_size: int = 100000):
        self.max_size = max_size
        self.cache = set()
        self.lru_queue = deque()
        self.lock = RLock()
        self.hits = 0
        self.misses = 0
    
    def contains(self, phrase_hash: str) -> bool:
        """Verifica se hash da frase est√° no cache"""
        with self.lock:
            if phrase_hash in self.cache:
                self.hits += 1
                # Mover para o final da queue (mais recente)
                if phrase_hash in self.lru_queue:
                    self.lru_queue.remove(phrase_hash)
                self.lru_queue.append(phrase_hash)
                return True
            else:
                self.misses += 1
                return False
    
    def add(self, phrase_hash: str):
        """Adiciona hash da frase ao cache"""
        with self.lock:
            if phrase_hash not in self.cache:
                if len(self.cache) >= self.max_size:
                    # Remover o mais antigo
                    oldest = self.lru_queue.popleft()
                    self.cache.remove(oldest)
                
                self.cache.add(phrase_hash)
                self.lru_queue.append(phrase_hash)
    
    def get_stats(self) -> dict:
        """Retorna estat√≠sticas do cache"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0
        return {
            "size": len(self.cache),
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate
        }

class OptimizedDatabaseManager:
    """Gerenciador otimizado da base de dados com transa√ß√µes em lote"""
    
    def __init__(self, db_path: str = None):
        self.db_path = db_path or CONFIG.get('database', 'path')
        self.batch_size = int(CONFIG.get('database', 'batch_size'))
        self.lock = RLock()
        self.pending_phrases = []
        self.pending_results = []
        self.cache = HighPerformanceCache(int(CONFIG.get('scanner', 'cache_size')))
        self.security = SecurityManager()
        self.last_backup = time.time()
        self.backup_interval = int(CONFIG.get('database', 'backup_interval'))
        
        self._init_database()
        self._load_cache_from_db()
    
    def _init_database(self):
        """Inicializa base de dados com otimiza√ß√µes"""
        with sqlite3.connect(self.db_path) as conn:
            # Configura√ß√µes de performance
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=NORMAL")
            conn.execute("PRAGMA cache_size=10000")
            conn.execute("PRAGMA temp_store=MEMORY")
            
            # Tabelas otimizadas
            conn.execute("""
                CREATE TABLE IF NOT EXISTS used_phrases (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    phrase_hash TEXT UNIQUE NOT NULL,
                    encrypted_phrase BLOB,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS wallet_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    phrase_hash TEXT NOT NULL,
                    address TEXT NOT NULL,
                    balance REAL NOT NULL,
                    derivation_path TEXT,
                    address_type TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(phrase_hash, address)
                )
            """)
            
            # √çndices otimizados
            conn.execute("CREATE INDEX IF NOT EXISTS idx_phrase_hash ON used_phrases(phrase_hash)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_balance ON wallet_results(balance)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON wallet_results(timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_address ON wallet_results(address)")
    
    def _load_cache_from_db(self):
        """Carrega hashes existentes para o cache"""
        logger.info("üîÑ Carregando cache da base de dados...")
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("SELECT phrase_hash FROM used_phrases")
            count = 0
            for row in cursor:
                self.cache.add(row[0])
                count += 1
        logger.info(f"‚úÖ Cache carregado: {count} frases")
    
    def is_phrase_used(self, phrase: str) -> bool:
        """Verifica se frase j√° foi usada (cache primeiro, depois BD)"""
        phrase_hash = hashlib.sha256(phrase.encode()).hexdigest()
        
        # Verificar cache primeiro
        if self.cache.contains(phrase_hash):
            return True
        
        # Se n√£o estiver no cache, verificar BD
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT 1 FROM used_phrases WHERE phrase_hash = ? LIMIT 1",
                (phrase_hash,)
            )
            exists = cursor.fetchone() is not None
            
            if exists:
                self.cache.add(phrase_hash)
            
            return exists
    
    def mark_phrase_used(self, phrase: str):
        """Marca frase como usada (em lote)"""
        phrase_hash = hashlib.sha256(phrase.encode()).hexdigest()
        
        # Adicionar ao cache imediatamente
        self.cache.add(phrase_hash)
        
        # Adicionar ao lote para grava√ß√£o
        encrypted_phrase = None
        if CONFIG.getboolean('security', 'encrypt_phrases'):
            encrypted_phrase = self.security.encrypt_phrase(phrase)
        
        with self.lock:
            self.pending_phrases.append((phrase_hash, encrypted_phrase))
            
            # Gravar lote quando atingir tamanho
            if len(self.pending_phrases) >= self.batch_size:
                self._flush_phrases()
    
    def _flush_phrases(self):
        """Grava lote de frases na BD"""
        if not self.pending_phrases:
            return
        
        with sqlite3.connect(self.db_path) as conn:
            conn.executemany(
                "INSERT OR IGNORE INTO used_phrases (phrase_hash, encrypted_phrase) VALUES (?, ?)",
                self.pending_phrases
            )
            conn.commit()
        
        logger.debug(f"üíæ Gravadas {len(self.pending_phrases)} frases na BD")
        self.pending_phrases.clear()
    
    def save_result(self, result: WalletResult):
        """Salva resultado em lote"""
        with self.lock:
            self.pending_results.append((
                result.phrase_hash,
                result.address,
                result.balance,
                result.derivation_path,
                result.address_type,
                result.timestamp
            ))
            
            if len(self.pending_results) >= self.batch_size:
                self._flush_results()
    
    def _flush_results(self):
        """Grava lote de resultados na BD"""
        if not self.pending_results:
            return
        
        with sqlite3.connect(self.db_path) as conn:
            conn.executemany("""
                INSERT OR IGNORE INTO wallet_results 
                (phrase_hash, address, balance, derivation_path, address_type, timestamp)
                VALUES (?, ?, ?, ?, ?, ?)
            """, self.pending_results)
            conn.commit()
        
        logger.debug(f"üíæ Gravados {len(self.pending_results)} resultados na BD")
        self.pending_results.clear()
    
    def flush_all(self):
        """For√ßa grava√ß√£o de todos os lotes pendentes"""
        with self.lock:
            self._flush_phrases()
            self._flush_results()
    
    def backup_database(self):
        """Cria backup da base de dados"""
        if time.time() - self.last_backup < self.backup_interval:
            return
        
        backup_path = f"{self.db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        try:
            import shutil
            shutil.copy2(self.db_path, backup_path)
            logger.info(f"üíæ Backup criado: {backup_path}")
            self.last_backup = time.time()
            
            # Limpar backups antigos (manter apenas os 5 mais recentes)
            backup_dir = Path(self.db_path).parent
            backups = sorted(backup_dir.glob(f"{Path(self.db_path).name}.backup_*"))
            for old_backup in backups[:-5]:
                old_backup.unlink()
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar backup: {e}")
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas completas"""
        self.flush_all()  # Garantir dados atualizados
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("SELECT COUNT(*) FROM used_phrases")
            total_checked = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(*) FROM wallet_results WHERE balance > 0")
            wallets_with_balance = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT SUM(balance) FROM wallet_results")
            total_balance = cursor.fetchone()[0] or 0
            
            cursor = conn.execute("SELECT COUNT(*) FROM wallet_results")
            total_results = cursor.fetchone()[0]
        
        cache_stats = self.cache.get_stats()
        
        return {
            "total_checked": total_checked,
            "total_results": total_results,
            "wallets_with_balance": wallets_with_balance,
            "total_balance_btc": total_balance,
            "cache_stats": cache_stats,
            "pending_phrases": len(self.pending_phrases),
            "pending_results": len(self.pending_results)
        }

class ModernCryptoUtils:
    """Utilit√°rios criptogr√°ficos usando bibliotecas modernas"""
    
    @staticmethod
    def mnemonic_to_addresses(mnemonic_phrase: str) -> Dict[str, str]:
        """Converte frase mnem√≥nica em m√∫ltiplos tipos de endere√ßos"""
        try:
            # Gerar seed
            seed_bytes = Bip39SeedGenerator(mnemonic_phrase).Generate()
            
            # Criar contexto BIP44 para Bitcoin
            bip44_mst_ctx = Bip44.FromSeed(seed_bytes, Bip44Coins.BITCOIN)
            bip44_acc_ctx = bip44_mst_ctx.Purpose().Coin().Account(0)
            bip44_chg_ctx = bip44_acc_ctx.Change(Bip44Changes.CHAIN_EXT)
            bip44_addr_ctx = bip44_chg_ctx.AddressIndex(0)
            
            addresses = {}
            
            # Endere√ßo P2PKH (Legacy - 1...)
            addresses['P2PKH'] = bip44_addr_ctx.PublicKey().ToAddress()
            
            # Endere√ßo P2WPKH (SegWit - bc1...)
            try:
                pubkey_hash = bip44_addr_ctx.PublicKey().RawCompressed().ToBytes()
                pubkey_hash160 = hashlib.new('ripemd160', hashlib.sha256(pubkey_hash).digest()).digest()
                addresses['P2WPKH'] = segwit_addr.encode('bc', 0, pubkey_hash160)
            except Exception as e:
                logger.warning(f"Erro ao gerar endere√ßo P2WPKH: {e}")
                addresses['P2WPKH'] = None
            
            return addresses
            
        except Exception as e:
            logger.error(f"Erro na convers√£o mnem√≥nica->endere√ßos: {e}")
            return {}

class RobustAPIClient:
    """Cliente robusto para APIs com retry e backoff exponencial"""
    
    def __init__(self):
        self.session = None
        self.timeout = int(CONFIG.get('api', 'timeout'))
        self.max_retries = int(CONFIG.get('api', 'max_retries'))
        self.backoff_factor = float(CONFIG.get('api', 'backoff_factor'))
        self.rate_limit_buffer = float(CONFIG.get('api', 'rate_limit_buffer'))
        
        self.apis = [
            {
                "name": "BlockCypher",
                "url": "https://api.blockcypher.com/v1/btc/main/addrs/{}/balance",
                "rate_limit": int(200 * self.rate_limit_buffer),
                "parser": self._parse_blockcypher,
                "weight": 1.0
            },
            {
                "name": "Blockchain.info",
                "url": "https://blockchain.info/rawaddr/{}?format=json",
                "rate_limit": int(300 * self.rate_limit_buffer),
                "parser": self._parse_blockchain_info,
                "weight": 0.8
            },
            {
                "name": "Blockstream",
                "url": "https://blockstream.info/api/address/{}",
                "rate_limit": int(100 * self.rate_limit_buffer),
                "parser": self._parse_blockstream,
                "weight": 0.9
            }
        ]
        
        self.current_api = 0
        self.request_counts = {i: 0 for i in range(len(self.apis))}
        self.last_reset = time.time()
        self.api_errors = {i: 0 for i in range(len(self.apis))}
    
    async def __aenter__(self):
        connector = aiohttp.TCPConnector(
            limit=200,
            limit_per_host=50,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={'User-Agent': 'BTC-Wallet-Scanner/2.0'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def _parse_blockcypher(self, data: dict) -> float:
        return data.get("final_balance", 0) / 1e8
    
    def _parse_blockchain_info(self, data: dict) -> float:
        return data.get("final_balance", 0) / 1e8
    
    def _parse_blockstream(self, data: dict) -> float:
        funded = data.get("chain_stats", {}).get("funded_txo_sum", 0)
        spent = data.get("chain_stats", {}).get("spent_txo_sum", 0)
        return (funded - spent) / 1e8
    
    def _select_best_api(self) -> int:
        """Seleciona a melhor API baseada em peso, erros e rate limits"""
        best_api = 0
        best_score = -1
        
        for i, api in enumerate(self.apis):
            # Verificar rate limit
            if self.request_counts[i] >= api["rate_limit"]:
                continue
            
            # Calcular score (peso - erro_rate)
            error_rate = self.api_errors[i] / max(1, self.request_counts[i])
            score = api["weight"] - error_rate
            
            if score > best_score:
                best_score = score
                best_api = i
        
        return best_api
    
    async def get_balance_with_retry(self, address: str) -> Optional[float]:
        """Obt√©m saldo com retry e backoff exponencial"""
        for attempt in range(self.max_retries):
            try:
                balance = await self.get_balance(address)
                if balance is not None:
                    return balance
            except Exception as e:
                if attempt == self.max_retries - 1:
                    logger.error(f"‚ùå Falha ap√≥s {self.max_retries} tentativas para {address}: {e}")
                    return None
                
                # Backoff exponencial
                wait_time = self.backoff_factor ** attempt + random.uniform(0, 1)
                await asyncio.sleep(wait_time)
        
        return None
    
    async def get_balance(self, address: str) -> Optional[float]:
        """Obt√©m saldo usando a melhor API dispon√≠vel"""
        if not self.session:
            return None
        
        # Reset contadores a cada hora
        if time.time() - self.last_reset > 3600:
            self.request_counts = {i: 0 for i in range(len(self.apis))}
            self.api_errors = {i: 0 for i in range(len(self.apis))}
            self.last_reset = time.time()
        
        api_index = self._select_best_api()
        api = self.apis[api_index]
        
        try:
            url = api["url"].format(address)
            async with self.session.get(url) as response:
                self.request_counts[api_index] += 1
                
                if response.status == 200:
                    data = await response.json()
                    balance = api["parser"](data)
                    return balance
                elif response.status == 429:
                    # Rate limit atingido
                    self.request_counts[api_index] = api["rate_limit"]
                    return None
                else:
                    self.api_errors[api_index] += 1
                    return None
                    
        except Exception as e:
            self.api_errors[api_index] += 1
            logger.warning(f"‚ö†Ô∏è Erro na API {api['name']}: {e}")
            return None

class OptimizedWalletScanner:
    """Scanner otimizado com todas as melhorias implementadas"""
    
    def __init__(self, max_workers: int = None):
        self.mnemo = Mnemonic("english")
        self.db = OptimizedDatabaseManager()
        self.crypto = ModernCryptoUtils()
        
        self.max_workers = max_workers or int(CONFIG.get('scanner', 'max_workers'))
        self.stats_interval = int(CONFIG.get('scanner', 'stats_interval'))
        
        self.stats = {
            "checked": 0,
            "found": 0,
            "start_time": time.time(),
            "total_balance": 0.0,
            "last_stats_time": time.time(),
            "addresses_per_phrase": 2  # P2PKH + P2WPKH
        }
        self.running = False
    
    def generate_unique_phrase(self) -> str:
        """Gera frase mnem√≥nica √∫nica otimizada"""
        max_attempts = 10000
        
        for attempt in range(max_attempts):
            # Gerar com entropia adicional para evitar colis√µes
            timestamp = int(time.time() * 1000000)
            random_bytes = os.urandom(16)
            combined_entropy = hashlib.sha256(
                timestamp.to_bytes(8, 'big') + random_bytes + attempt.to_bytes(4, 'big')
            ).digest()[:16]
            
            phrase = self.mnemo.to_mnemonic(combined_entropy)
            
            if not self.db.is_phrase_used(phrase):
                return phrase
        
        # Fallback extremo - usar timestamp √∫nico
        unique_entropy = hashlib.sha256(
            f"fallback_{time.time()}_{os.urandom(32).hex()}".encode()
        ).digest()[:16]
        
        return self.mnemo.to_mnemonic(unique_entropy)
    
    async def check_wallet_comprehensive(self, api_client: RobustAPIClient) -> List[WalletResult]:
        """Verifica uma carteira com m√∫ltiplos tipos de endere√ßos"""
        results = []
        
        try:
            # Gerar frase √∫nica
            phrase = self.generate_unique_phrase()
            phrase_hash = hashlib.sha256(phrase.encode()).hexdigest()
            self.db.mark_phrase_used(phrase)
            
            # Gerar m√∫ltiplos endere√ßos
            addresses = self.crypto.mnemonic_to_addresses(phrase)
            
            if not addresses:
                return results
            
            # Verificar cada tipo de endere√ßo
            for addr_type, address in addresses.items():
                if not address:
                    continue
                
                try:
                    balance = await api_client.get_balance_with_retry(address)
                    if balance is None:
                        continue
                    
                    result = WalletResult(
                        phrase_hash=phrase_hash,
                        address=address,
                        balance=balance,
                        timestamp=datetime.now().isoformat(),
                        address_type=addr_type
                    )
                    
                    # Salvar resultado
                    self.db.save_result(result)
                    results.append(result)
                    
                    # Atualizar estat√≠sticas
                    if balance > 0:
                        self.stats["found"] += 1
                        self.stats["total_balance"] += balance
                        
                        # Log resultado importante
                        results_logger.info(
                            f"üí∞ CARTEIRA ENCONTRADA! "
                            f"Tipo: {addr_type}, Saldo: {balance:.8f} BTC, "
                            f"Endere√ßo: {address}, Hash: {phrase_hash[:16]}..."
                        )
                        
                        print(f"üéâ SUCESSO! {addr_type}: {balance:.8f} BTC - {address}")
                
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao verificar {addr_type} {address}: {e}")
                    continue
            
            self.stats["checked"] += 1
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o de carteira: {e}")
            return results
    
    async def scan_batch_optimized(self, batch_size: int = 50):
        """Verifica lote de carteiras com m√°xima otimiza√ß√£o"""
        async with RobustAPIClient() as api_client:
            semaphore = asyncio.Semaphore(self.max_workers)
            
            async def scan_with_semaphore():
                async with semaphore:
                    return await self.check_wallet_comprehensive(api_client)
            
            # Executar lote
            tasks = [scan_with_semaphore() for _ in range(batch_size)]
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Processar resultados
            total_results = []
            for result in batch_results:
                if isinstance(result, list):
                    total_results.extend(result)
                elif isinstance(result, Exception):
                    logger.warning(f"‚ö†Ô∏è Exce√ß√£o no lote: {result}")
            
            return total_results
    
    def print_comprehensive_stats(self):
        """Imprime estat√≠sticas completas e otimizadas"""
        current_time = time.time()
        elapsed = current_time - self.stats["start_time"]
        interval_elapsed = current_time - self.stats["last_stats_time"]
        
        rate = self.stats["checked"] / elapsed if elapsed > 0 else 0
        addresses_rate = (self.stats["checked"] * self.stats["addresses_per_phrase"]) / elapsed if elapsed > 0 else 0
        
        print(f"\n{'='*60}")
        print(f"üìä ESTAT√çSTICAS DETALHADAS - {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*60}")
        print(f"‚è±Ô∏è  Tempo total: {elapsed:.1f}s | Intervalo: {interval_elapsed:.1f}s")
        print(f"üîç Frases verificadas: {self.stats['checked']:,}")
        print(f"üè† Endere√ßos verificados: {self.stats['checked'] * self.stats['addresses_per_phrase']:,}")
        print(f"üí∞ Carteiras com saldo: {self.stats['found']:,}")
        print(f"üìà Taxa: {rate:.1f} frases/s | {addresses_rate:.1f} endere√ßos/s")
        print(f"üíµ Saldo total: {self.stats['total_balance']:.8f} BTC")
        
        # Estat√≠sticas da base de dados
        db_stats = self.db.get_stats()
        cache_stats = db_stats['cache_stats']
        
        print(f"\nüìö BASE DE DADOS:")
        print(f"   ‚Ä¢ Total verificado: {db_stats['total_checked']:,}")
        print(f"   ‚Ä¢ Resultados salvos: {db_stats['total_results']:,}")
        print(f"   ‚Ä¢ Pendentes: {db_stats['pending_phrases']} frases, {db_stats['pending_results']} resultados")
        
        print(f"\nüöÄ CACHE DE PERFORMANCE:")
        print(f"   ‚Ä¢ Tamanho: {cache_stats['size']:,}/{int(CONFIG.get('scanner', 'cache_size')):,}")
        print(f"   ‚Ä¢ Taxa de acerto: {cache_stats['hit_rate']:.1f}%")
        print(f"   ‚Ä¢ Hits: {cache_stats['hits']:,} | Misses: {cache_stats['misses']:,}")
        
        # Probabilidade estat√≠stica
        total_possible = 2**128  # Para frases de 12 palavras
        probability = (self.stats['checked'] / total_possible) * 100
        print(f"\nüéØ AN√ÅLISE ESTAT√çSTICA:")
        print(f"   ‚Ä¢ Espa√ßo explorado: {probability:.2e}% do total poss√≠vel")
        print(f"   ‚Ä¢ Pr√≥xima verifica√ß√£o estimada: {rate*3600:.0f} frases/hora")
        
        print(f"{'='*60}\n")
        self.stats["last_stats_time"] = current_time
    
    async def run_continuous_optimized(self, batch_size: int = 50, stats_frequency: int = 10):
        """Execu√ß√£o cont√≠nua com todas as otimiza√ß√µes"""
        self.running = True
        logger.info(f"üöÄ Scanner Otimizado iniciado!")
        logger.info(f"   ‚Ä¢ Workers: {self.max_workers}")
        logger.info(f"   ‚Ä¢ Lote: {batch_size} frases")
        logger.info(f"   ‚Ä¢ Cache: {CONFIG.get('scanner', 'cache_size')} entradas")
        logger.info(f"   ‚Ä¢ Encripta√ß√£o: {'Ativada' if CONFIG.getboolean('security', 'encrypt_phrases') else 'Desativada'}")
        
        batch_count = 0
        
        try:
            while self.running:
                # Executar lote
                start_batch = time.time()
                results = await self.scan_batch_optimized(batch_size)
                batch_time = time.time() - start_batch
                
                batch_count += 1
                
                # Estat√≠sticas a cada N lotes
                if batch_count % stats_frequency == 0:
                    self.print_comprehensive_stats()
                    
                    # Fazer backup periodicamente
                    self.db.backup_database()
                    
                    # Log de performance do lote
                    batch_rate = batch_size / batch_time if batch_time > 0 else 0
                    logger.info(f"üì¶ Lote {batch_count}: {batch_size} frases em {batch_time:.2f}s ({batch_rate:.1f} frases/s)")
                
                # Pequeno delay adaptativo baseado na performance
                if batch_time < 1.0:
                    await asyncio.sleep(0.1)  # Sistema muito r√°pido
                elif batch_time > 10.0:
                    await asyncio.sleep(1.0)   # Sistema sobrecarregado
                else:
                    await asyncio.sleep(0.5)   # Performance normal
                
        except KeyboardInterrupt:
            logger.info("üõë Parando scanner...")
            self.running = False
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no scanner: {e}")
            self.running = False
        finally:
            # Limpeza final
            self.db.flush_all()
            self.print_comprehensive_stats()
            logger.info("‚úÖ Scanner finalizado com sucesso")
    
    def stop(self):
        """Para a execu√ß√£o e salva estado"""
        self.running = False
        self.db.flush_all()

class SystemMonitor:
    """Monitor de sistema para otimiza√ß√£o de recursos"""
    
    @staticmethod
    def get_optimal_workers() -> int:
        """Calcula n√∫mero √≥timo de workers baseado nos recursos"""
        try:
            import psutil
            
            # CPU
            cpu_count = psutil.cpu_count(logical=True)
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # Mem√≥ria
            memory = psutil.virtual_memory()
            memory_available_gb = memory.available / (1024**3)
            
            # Calcular workers √≥timos
            if memory_available_gb < 2:
                return max(2, cpu_count // 2)  # Pouca mem√≥ria
            elif memory_available_gb < 4:
                return max(4, cpu_count)       # Mem√≥ria m√©dia
            else:
                return min(64, cpu_count * 4)  # Muita mem√≥ria
                
        except ImportError:
            # Fallback se psutil n√£o estiver dispon√≠vel
            return min(32, cpu_count() * 2)
    
    @staticmethod
    def print_system_info():
        """Imprime informa√ß√µes do sistema"""
        try:
            import psutil
            
            print(f"üíª INFORMA√á√ïES DO SISTEMA:")
            print(f"   ‚Ä¢ CPU: {psutil.cpu_count()} cores ({psutil.cpu_count(logical=True)} threads)")
            print(f"   ‚Ä¢ RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB total")
            print(f"   ‚Ä¢ RAM dispon√≠vel: {psutil.virtual_memory().available / (1024**3):.1f} GB")
            print(f"   ‚Ä¢ Uso CPU: {psutil.cpu_percent()}%")
            
        except ImportError:
            print(f"üíª CPU cores detectados: {cpu_count()}")

def print_banner():
    """Imprime banner da aplica√ß√£o"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                               ‚ïë
‚ïë    üîç SISTEMA PROFISSIONAL DE VERIFICA√á√ÉO DE CARTEIRAS BTC    ‚ïë
‚ïë                        Vers√£o Otimizada 2.0                  ‚ïë
‚ïë                                                               ‚ïë
‚ïë  ‚ö° Performance M√°xima | üîí Seguran√ßa Avan√ßada | üìä Analytics ‚ïë
‚ïë                                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """
    print(banner)

async def main():
    """Fun√ß√£o principal otimizada"""
    print_banner()
    
    # Informa√ß√µes do sistema
    SystemMonitor.print_system_info()
    
    print(f"\n‚öôÔ∏è CONFIGURA√á√ÉO ATUAL:")
    print(f"   ‚Ä¢ Base de dados: {CONFIG.get('database', 'path')}")
    print(f"   ‚Ä¢ Cache size: {CONFIG.get('scanner', 'cache_size')} entradas")
    print(f"   ‚Ä¢ Encripta√ß√£o: {'‚úÖ' if CONFIG.getboolean('security', 'encrypt_phrases') else '‚ùå'}")
    print(f"   ‚Ä¢ Timeout API: {CONFIG.get('api', 'timeout')}s")
    print(f"   ‚Ä¢ Max retries: {CONFIG.get('api', 'max_retries')}")
    
    # Input do utilizador com valida√ß√£o
    print(f"\nüîß CONFIGURA√á√ÉO DA SESS√ÉO:")
    
    try:
        batch_input = input("Tamanho do lote (padr√£o 50): ").strip()
        batch_size = int(batch_input) if batch_input else 50
        batch_size = max(1, min(1000, batch_size))  # Limitar entre 1-1000
        
        workers_input = input(f"Workers (padr√£o {SystemMonitor.get_optimal_workers()}): ").strip()
        max_workers = int(workers_input) if workers_input else SystemMonitor.get_optimal_workers()
        max_workers = max(1, min(200, max_workers))  # Limitar entre 1-200
        
        stats_input = input("Frequ√™ncia de stats (padr√£o 10 lotes): ").strip()
        stats_freq = int(stats_input) if stats_input else 10
        stats_freq = max(1, min(100, stats_freq))
        
    except ValueError:
        print("‚ö†Ô∏è Valores inv√°lidos, usando padr√µes...")
        batch_size = 50
        max_workers = SystemMonitor.get_optimal_workers()
        stats_freq = 10
    
    # Mostrar configura√ß√£o final
    print(f"\nüöÄ CONFIGURA√á√ÉO FINAL:")
    print(f"   ‚Ä¢ Lote: {batch_size} frases por vez")
    print(f"   ‚Ä¢ Workers: {max_workers} paralelos")
    print(f"   ‚Ä¢ Stats: a cada {stats_freq} lotes")
    print(f"   ‚Ä¢ Endere√ßos por frase: 2 (P2PKH + P2WPKH)")
    print(f"   ‚Ä¢ Taxa estimada: ~{batch_size * 2 * max_workers / 10:.0f} endere√ßos/minuto")
    
    print(f"\n{'='*60}")
    print("üéØ PRESSIONE ENTER PARA INICIAR | Ctrl+C PARA PARAR")
    print(f"{'='*60}")
    input()
    
    # Criar e executar scanner
    scanner = OptimizedWalletScanner(max_workers=max_workers)
    
    try:
        await scanner.run_continuous_optimized(
            batch_size=batch_size, 
            stats_frequency=stats_freq
        )
    except KeyboardInterrupt:
        print("\nüëã Scanner interrompido pelo utilizador")
    except Exception as e:
        logger.error(f"‚ùå Erro cr√≠tico: {e}")
        print(f"\n‚ùå Erro cr√≠tico: {e}")
    
    # Relat√≥rio final
    print(f"\n{'='*60}")
    print("üìã RELAT√ìRIO FINAL DA SESS√ÉO")
    print(f"{'='*60}")
    scanner.print_comprehensive_stats()
    
    # Estat√≠sticas da base de dados
    db_stats = scanner.db.get_stats()
    if db_stats['wallets_with_balance'] > 0:
        print("üéâ CARTEIRAS ENCONTRADAS NESTA SESS√ÉO!")
        print("   Verifique o ficheiro 'logs/found_wallets.log' para detalhes completos.")
    else:
        print("üìù Nenhuma carteira com saldo encontrada nesta sess√£o.")
        print("   Continue a verifica√ß√£o - cada tentativa aumenta as probabilidades!")

def run_tests():
    """Executa testes b√°sicos do sistema"""
    print("üß™ Executando testes do sistema...\n")
    
    # Teste 1: Gera√ß√£o de frases
    print("1Ô∏è‚É£ Testando gera√ß√£o de frases mnem√≥nicas...")
    mnemo = Mnemonic("english")
    phrase = mnemo.generate(strength=128)
    print(f"   ‚úÖ Frase gerada: {phrase[:50]}...")
    
    # Teste 2: Deriva√ß√£o de endere√ßos
    print("2Ô∏è‚É£ Testando deriva√ß√£o de endere√ßos...")
    crypto = ModernCryptoUtils()
    addresses = crypto.mnemonic_to_addresses(phrase)
    print(f"   ‚úÖ P2PKH: {addresses.get('P2PKH', 'Erro')}")
    print(f"   ‚úÖ P2WPKH: {addresses.get('P2WPKH', 'Erro')}")
    
    # Teste 3: Base de dados
    print("3Ô∏è‚É£ Testando base de dados...")
    db = OptimizedDatabaseManager("test_wallets.db")
    db.mark_phrase_used("test phrase for database")
    is_used = db.is_phrase_used("test phrase for database")
    print(f"   ‚úÖ Grava√ß√£o e leitura: {'OK' if is_used else 'ERRO'}")
    
    # Teste 4: Cache
    print("4Ô∏è‚É£ Testando cache...")
    cache = HighPerformanceCache(1000)
    cache.add("test_hash")
    has_item = cache.contains("test_hash")
    print(f"   ‚úÖ Cache: {'OK' if has_item else 'ERRO'}")
    
    # Limpeza
    try:
        os.remove("test_wallets.db")
    except:
        pass
    
    print("\n‚úÖ Todos os testes conclu√≠dos com sucesso!")
    print("üöÄ Sistema pronto para uso em produ√ß√£o.\n")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        run_tests()
    else:
        # Executar aplica√ß√£o principal
        try:
            asyncio.run(main())
        except KeyboardInterrupt:
            print("\nüëã Aplica√ß√£o encerrada pelo utilizador")
        except Exception as e:
            logger.error(f"‚ùå Erro fatal: {e}")
            print(f"‚ùå Erro fatal: {e}")
            sys.exit(1)
